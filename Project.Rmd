---
title: "Project"
author: "Gabriela Maślanka, Karolina Gajewska"
date: "`r Sys.Date()`"
output:
  html_document: 
    code_folding: hide
    theme: paper
---
### Wstęp

Celem niniejszej pracy jest osiągnięcie jak najbardziej precyzyjnej prognozy dotyczącej charakteru nowotworu piersi u kobiet, opartej na zebranych danych dotyczących zmian nowotworowych.

Biblioteki użyte w projekcie:
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
library(psych)
library(corrplot)
```

### Opis danych 
Dane na których możemy budować nasz model to:

*zmienne objaśniające*:

*mean_radius*: Średni rozmiar guza, istotny dla oceny jego wielkości.

*mean_texture*: Jednorodność komórek guza, mierzona wartością tekstury.

*mean_perimeter*: Zewnętrzna długość krzywej guza, informująca o jego kształcie.

*mean_area*: Przestrzenny rozmiar guza, wyrażony jako średnia powierzchnia.

*mean_smoothness*: Stopień równomierności komórek, określający gładkość guza.

*Zmienna objaśniana:*

*diagnosis*: Zmienna binarna (0-1) określająca czy zmiana nowotworowa zostałą rozpoznana jako łagodna (0) czy złośliwa (1) .

Na początku sprawdzamy, czy w naszym zbiorze danych zmienne objaśniające mają wpływ na zmienną objaśnianą. Wykorzystujemy do tego model regresji liniowej.
```{r message=FALSE, warning=FALSE}
set.seed(1)
data<-read.csv("Breast_cancer_data.csv", header = TRUE, sep = ",",dec = ".")
data$diagnosis<- as.factor(data$diagnosis)
index <- sample(nrow(data), 450, replace = F)
train <- data[index,]
test <- data[-index,]

model <- glm(diagnosis ~ mean_radius + mean_texture + mean_perimeter + mean_area + mean_smoothness, 
             data, 
             family = "binomial")
summary(model)
```
Zauważamy, że wszystkie zmienne wpływają na wynik zmiennej objaśnianej.

Wykonujemy również macierz korelacji:
```{r}
data$diagnosis_numeric <- as.numeric(data$diagnosis)

correlation <- cor(data[, c("mean_radius", "mean_texture", "mean_perimeter", "mean_area", "mean_smoothness", "diagnosis_numeric")])


corrplot(correlation, method = "color", type = "upper", order = "hclust")
```

#### Przygotowanie danych
W celu przygotowania danych sprawdzamy, czy występują braki danych.
```{r}
any(is.na(data))
```
W zbiorze danych nie posiadamy braków.

Następnie wykonujemy wykresy pudełkowe aby sprawdzić, czy zmienne zawierają wartości odstające.
```{r}
data_positive <- data[data$diagnosis==1,]
data_negative <- data[data$diagnosis==0,]
par(mfrow = c(2, 3))
for (nazwa_zmiennej in colnames(data_positive)) {
  boxplot(data_positive[[nazwa_zmiennej]], main = nazwa_zmiennej)
}
for (nazwa_zmiennej in colnames(data_negative)) {
  boxplot(data_negative[[nazwa_zmiennej]], main = nazwa_zmiennej)
}
```


```{r}
par(mfrow = c(1, 1))
```
Usuwamy wartości odstające oraz standaryzujemy dane.
```{r}
usuń_odstające <- function(dane) {
  for (nazwa_zmiennej in colnames(dane)) {
    if (nazwa_zmiennej != "diagnosis") {  # Sprawdzenie, czy kolumna nie jest "diagnosis"
      Q1 <- quantile(dane[[nazwa_zmiennej]], 0.25)
      Q3 <- quantile(dane[[nazwa_zmiennej]], 0.75)
      IQR_value <- Q3 - Q1

      # Określenie granic wartości odstających
      dolna_granica <- Q1 - 1.5 * IQR_value
      gorna_granica <- Q3 + 1.5 * IQR_value

      # Usunięcie wartości odstających
      dane <- dane[!(dane[[nazwa_zmiennej]] < dolna_granica | dane[[nazwa_zmiennej]] > gorna_granica), ]
    }
  }
  return(dane)
}

data_positive_clear<- usuń_odstające(data_positive)
data_negative_clear<- usuń_odstające(data_negative)

data_clear <- rbind(data_positive_clear, data_negative_clear)
data_clear$mean_radius<- scale(data_clear$mean_radius)
data_clear$mean_texture<- scale(data_clear$mean_texture)
data_clear$mean_perimeter<- scale(data_clear$mean_perimeter)
data_clear$mean_area<- scale(data_clear$mean_area)
data_clear$mean_smoothness<- scale(data_clear$mean_smoothness)
```
Podstawowe statystyki na zbiorze danych.

```{r}
describe(select(data, -diagnosis))
prop.table(table(data$diagnosis))
```
Kiedy skalowanie???

#### Podział na zbiór uczący oraz testowy
Zbiór został podzielony w proporcji 80:20
```{r}
index <- sample(nrow(data), 420, replace = F)
train <- data[index,]
test <- data[-index,]
```

Następnie porównujemy podstawowe statystyki w obu grupach.
```{r}
describe(select(train, -diagnosis))
prop.table(table(train$diagnosis))
describe(select(test, -diagnosis))
prop.table(table(test$diagnosis))
```

